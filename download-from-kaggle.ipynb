{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T04:57:17.675900Z",
     "iopub.status.busy": "2025-11-15T04:57:17.675467Z",
     "iopub.status.idle": "2025-11-15T04:57:18.919749Z",
     "shell.execute_reply": "2025-11-15T04:57:18.918503Z",
     "shell.execute_reply.started": "2025-11-15T04:57:17.675864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Create the correct directory\n",
    "!mkdir -p /root/.kaggle\n",
    "\n",
    "# Create the kaggle.json file with your credentials\n",
    "kaggle_json = {\n",
    "    \"username\": \"skbahmed\",\n",
    "    \"key\": \"312312312312312312312321\"  # Replace with your real API key\n",
    "}\n",
    "\n",
    "# Write to the CORRECT location\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "    json.dump(kaggle_json, f)\n",
    "\n",
    "# Set appropriate permissions\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# Verify it was created correctly\n",
    "!ls -la /root/.kaggle/\n",
    "\n",
    "# Test authentication\n",
    "!kaggle kernels list --mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Verify your Kaggle credentials are set up\n",
    "!ls -la ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T04:57:29.090668Z",
     "iopub.status.busy": "2025-11-15T04:57:29.089903Z",
     "iopub.status.idle": "2025-11-15T05:00:40.592078Z",
     "shell.execute_reply": "2025-11-15T05:00:40.588562Z",
     "shell.execute_reply.started": "2025-11-15T04:57:29.090613Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file downloaded to /kaggle/working/data/my_ner_dataset-0001/class_mapping.py\n",
      "Output file downloaded to /kaggle/working/data/my_ner_dataset-0001/conll_files/sampled.conll\n",
      "Output file downloaded to /kaggle/working/data/my_ner_dataset-0001/conll_files/test.conll\n",
      "Output file downloaded to /kaggle/working/data/my_ner_dataset-0001/conll_files/train.conll\n",
      "Output file downloaded to /kaggle/working/data/my_ner_dataset-0001/conll_files/val.conll\n",
      "Output file downloaded to /kaggle/working/data/my_ner_dataset-0001/test.json\n",
      "Output file downloaded to /kaggle/working/data/my_ner_dataset-0001/train.json\n",
      "Output file downloaded to /kaggle/working/data/my_ner_dataset-0001/val.json\n",
      "Output file downloaded to /kaggle/working/logs/events.out.tfevents.1757060091.6a1cd0e2ded0.19.0\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/config.json\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/merges.txt\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/model.safetensors\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/optimizer.pt\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/rng_state.pth\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/scaler.pt\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/scheduler.pt\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/special_tokens_map.json\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/tokenizer.json\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/tokenizer_config.json\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/trainer_state.json\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/training_args.bin\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-2625/vocab.json\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/config.json\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/merges.txt\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/model.safetensors\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/optimizer.pt\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/rng_state.pth\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/scaler.pt\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/scheduler.pt\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/special_tokens_map.json\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/tokenizer.json\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/tokenizer_config.json\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/trainer_state.json\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/training_args.bin\n",
      "Output file downloaded to /kaggle/working/results/checkpoint-730/vocab.json\n",
      "Output file downloaded to /kaggle/working/sampled.conll\n",
      "Kernel log downloaded to /kaggle/working/hf-ner-uk-garawise-roberta-base.log \n"
     ]
    }
   ],
   "source": [
    "!kaggle kernels output skbahmed/hf-ner-uk-garawise-roberta-base -p /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T05:01:31.738408Z",
     "iopub.status.busy": "2025-11-15T05:01:31.737512Z",
     "iopub.status.idle": "2025-11-15T05:03:32.183369Z",
     "shell.execute_reply": "2025-11-15T05:03:32.182322Z",
     "shell.execute_reply.started": "2025-11-15T05:01:31.738359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder '/kaggle/working/results/checkpoint-2625' has been zipped to 'checkpoint-2625.zip'\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Function to zip a folder without downloading\n",
    "def zip_folder(folder_path, output_zip_name):\n",
    "    \"\"\"\n",
    "    Zip an entire folder in Colab\n",
    "\n",
    "    Args:\n",
    "        folder_path: Path to the folder you want to zip\n",
    "        output_zip_name: Name for the output zip file\n",
    "    \"\"\"\n",
    "    # Create a ZipFile object\n",
    "    with zipfile.ZipFile(output_zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Walk through the directory\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # Create the full file path\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Calculate path within the zip file\n",
    "                arcname = os.path.relpath(file_path, os.path.dirname(folder_path))\n",
    "                # Add file to zip\n",
    "                zipf.write(file_path, arcname)\n",
    "\n",
    "    print(f\"Folder '{folder_path}' has been zipped to '{output_zip_name}'\")\n",
    "\n",
    "# Example usage\n",
    "zip_folder('/kaggle/working/results/checkpoint-2625', 'checkpoint-2625.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T05:06:11.743247Z",
     "iopub.status.busy": "2025-11-15T05:06:11.742797Z",
     "iopub.status.idle": "2025-11-15T05:06:23.298256Z",
     "shell.execute_reply": "2025-11-15T05:06:23.296457Z",
     "shell.execute_reply.started": "2025-11-15T05:06:11.743219Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_mapping.py: Skipping, found more recently modified local copy (use --force to force download)\n",
      "sampled.conll: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test.conll: Skipping, found more recently modified local copy (use --force to force download)\n",
      "train.conll: Skipping, found more recently modified local copy (use --force to force download)\n",
      "val.conll: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "train.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "val.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "events.out.tfevents.1757060091.6a1cd0e2ded0.19.0: Skipping, found more recently modified local copy (use --force to force download)\n",
      "config.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "merges.txt: Skipping, found more recently modified local copy (use --force to force download)\n",
      "model.safetensors: Skipping, found more recently modified local copy (use --force to force download)\n",
      "optimizer.pt: Skipping, found more recently modified local copy (use --force to force download)\n",
      "rng_state.pth: Skipping, found more recently modified local copy (use --force to force download)\n",
      "scaler.pt: Skipping, found more recently modified local copy (use --force to force download)\n",
      "scheduler.pt: Skipping, found more recently modified local copy (use --force to force download)\n",
      "special_tokens_map.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "tokenizer.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "tokenizer_config.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "trainer_state.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "training_args.bin: Skipping, found more recently modified local copy (use --force to force download)\n",
      "vocab.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "config.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "merges.txt: Skipping, found more recently modified local copy (use --force to force download)\n",
      "model.safetensors: Skipping, found more recently modified local copy (use --force to force download)\n",
      "optimizer.pt: Skipping, found more recently modified local copy (use --force to force download)\n",
      "rng_state.pth: Skipping, found more recently modified local copy (use --force to force download)\n",
      "scaler.pt: Skipping, found more recently modified local copy (use --force to force download)\n",
      "scheduler.pt: Skipping, found more recently modified local copy (use --force to force download)\n",
      "special_tokens_map.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "tokenizer.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "tokenizer_config.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "trainer_state.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "training_args.bin: Skipping, found more recently modified local copy (use --force to force download)\n",
      "vocab.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "sampled.conll: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Kernel log downloaded to /kaggle/working/hf-ner-uk-garawise-roberta-base.log \n"
     ]
    }
   ],
   "source": [
    "!kaggle kernels output skbahmed/hf-ner-uk-garawise-roberta-base/results/checkpoint-12240 -p /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
